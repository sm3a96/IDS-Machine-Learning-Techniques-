{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2055648/4127825478.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-27 18:38:21.836560: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-27 18:38:21.872823: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 18:38:21.872866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 18:38:21.873934: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 18:38:21.880492: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 18:38:22.756616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "# This code is written in Python 3.7. To install the required packages, run the following commands:\n",
    "# pip install pandas numpy matplotlib seaborn scikit-learn sympy\n",
    "# This code is applicable to the Simargl 2022 dataset. \n",
    "# implemented Advanced Ensemble techniques: Blending\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned Simargl 2022 dataset\n",
    "df = pd.read_csv(\n",
    "    '/home/ibibers@ads.iu.edu/IDS_Datasets/Combined_datasets/Simargl_cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extract subsample of data: \n",
      "ALERT\n",
      "Normal               15049330\n",
      "Denial of Service     5138973\n",
      "Port Scanning         4170194\n",
      "Malware                   571\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract subsample of data\n",
    "print (\" Extract subsample of data: \")\n",
    "print(df['ALERT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALERT\n",
      "Normal               15049330\n",
      "Denial of Service     5138973\n",
      "Port Scanning         4170194\n",
      "Malware                   571\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dropped_df = ['ALERT']\n",
    "X = df.drop(dropped_df, axis=1)\n",
    "y = df['ALERT']\n",
    "\n",
    "# # Label encoding for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(df['ALERT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 18:40:04.566806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1046 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:67:00.0, compute capability: 8.6\n",
      "2024-02-27 18:40:04.567513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1047 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:68:00.0, compute capability: 8.6\n",
      "2024-02-27 18:40:16.291982: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.96GiB (rounded to 2104623616)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-02-27 18:40:16.292067: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-02-27 18:40:16.292089: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292102: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292112: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292122: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292133: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292143: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292153: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292164: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292174: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292184: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292195: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292205: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292215: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292225: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292235: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292245: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292256: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292266: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292276: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292305: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-27 18:40:16.292319: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 1.96GiB was 256.00MiB, Chunk State: \n",
      "2024-02-27 18:40:16.292328: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-02-27 18:40:16.292336: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 0B\n",
      "2024-02-27 18:40:16.292347: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 0 memory_limit_: 1096941568 available bytes: 1096941568 curr_region_allocation_bytes_: 1096941568\n",
      "2024-02-27 18:40:16.292361: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      1096941568\n",
      "InUse:                               0\n",
      "MaxInUse:                            0\n",
      "NumAllocs:                           0\n",
      "MaxAllocSize:                        0\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-02-27 18:40:16.292370: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] <allocator contains no memory>\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      3\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert data to TensorFlow tensors\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m X_train_tf \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_train_tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(pd\u001b[38;5;241m.\u001b[39mfactorize(y_train)[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m      8\u001b[0m X_test_tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(X_test\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "\n",
    "# Initial train test split set and split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Initialize MirroredStrategy for GPU acceleration\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Train the models\n",
    "with strategy.scope():\n",
    "    # the base models\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    mlpc_model = MLPClassifier(random_state=42)\n",
    "    Lr_model = LogisticRegression(random_state=42)\n",
    "    dst_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Train base models on the training set\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    mlpc_model.fit(X_train, y_train)\n",
    "    Lr_model.fit(X_train, y_train)\n",
    "    dst_model.fit(X_train, y_train)\n",
    "\n",
    "    # predictions on the test set\n",
    "    pred1 = rf_model.predict(X_test)\n",
    "    pred2 = mlpc_model.predict(X_test)\n",
    "    pred3 = Lr_model.predict(X_test)\n",
    "    pred4 = dst_model.predict(X_test)\n",
    "\n",
    "    # here is the blending part starts, create a new dataset with the predictions of base models\n",
    "    blend_X_train = np.column_stack((pred1, pred2, pred3, pred4))\n",
    "\n",
    "    # meta_model = LogisticRegression(random_state=42)\n",
    "    meta_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Train the meta-model on the blended predictions\n",
    "    meta_model.fit(blend_X_train, y_test)\n",
    "\n",
    "    # Now, let's make predictions on the test set using the base models\n",
    "    base_rf_model_pred = rf_model.predict(X_test)\n",
    "    base_mlpc_model_pred = mlpc_model.predict(X_test)\n",
    "    base_Lr_model_pred = Lr_model.predict(X_test)\n",
    "    base_dst_model_pred = dst_model.predict(X_test)\n",
    "\n",
    "    # Create a new dataset with the predictions of base models for the meta-model\n",
    "    blend_X_test = np.column_stack(\n",
    "        (base_rf_model_pred, base_mlpc_model_pred, base_Lr_model_pred, base_dst_model_pred))\n",
    "\n",
    "    # predictions on the test set using the meta-model\n",
    "    y_pred_encoded = meta_model.predict(blend_X_test)\n",
    "\n",
    "\n",
    "\n",
    "# # Convert probabilities to TensorFlow tensors\n",
    "# pred_tf = tf.convert_to_tensor(y_pred_enc, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_encoded)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use inverse_transform to get original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use inverse_transform to get original labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "y_test_labels = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix with string labels\n",
    "conf_mat = confusion_matrix(y_test_labels, y_pred)\n",
    "\n",
    "# Get unique class labels from y_test and y_pred_encoded\n",
    "unique_labels = np.unique(np.concatenate(\n",
    "    (y_test_labels, y_pred)))\n",
    "\n",
    "# Plotting the Confusion Matrix with class labels\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature importances from base models\n",
    "base_models_importances = {}\n",
    "\n",
    "for i, model in enumerate([rf_model, Lr_model, dst_model, mlpc_model]):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        base_models_importances[f'base_model_{i}'] = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "importance_df = pd.DataFrame(base_models_importances, index=X.columns)\n",
    "\n",
    "# Calculate average feature importance across base models\n",
    "average_importance = importance_df.mean(axis=1)\n",
    "\n",
    "# Sort features by average importance\n",
    "sorted_importance = average_importance.sort_values(ascending=False)\n",
    "\n",
    "# Visualize the feature importances\n",
    "plt.figure(figsize=(14, 20))\n",
    "sns.barplot(x=sorted_importance.values,\n",
    "            y=sorted_importance.index, palette='mako')\n",
    "plt.xlabel('Average Importance Value')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Average Feature Importance in Blending Model')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
